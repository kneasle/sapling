//! Automated random testing and benchmarking for various components of Sapling (tokenizers,
//! parsers, etc.).
//!
//! TODO: Replace this with `quickcheck` or `proptest`?

mod parser;
mod tokenizer;
mod utils;

use std::time::{Duration, Instant};

use rand::Rng;
use sapling::Lang;

fn main() {
    let lang = Lang::load_toml_file("json.toml").unwrap();

    let fuzz_tokenizer = false;

    // Average length should be around 10k tokens, and run 10k iterations
    if fuzz_tokenizer {
        tokenizer::fuzz(&lang, Some(10_000), 10_000.0);
    } else {
        parser::fuzz(&lang, Some(10_000));
    }
}

pub trait Arbitrary<'lang>: Sized + Eq {
    /// Configuration parameters passed into the [`fuzz`] function
    type Config: Default;
    /// Static data generated once before entering the fuzzing loop
    type StaticData;
    /// Sample tables generated every couple of thousand fuzzing iterations.  This allows the
    /// program to cache commonly computed values (e.g. whitespace) to speed up sample generation.
    type SampleTable;

    fn gen_static_data(lang: &'lang Lang, config: &Self::Config) -> Self::StaticData;
    fn gen_table(
        data: &Self::StaticData,
        rng: &mut impl Rng,
        config: &Self::Config,
    ) -> Self::SampleTable;

    /// Create a new sample to test
    fn gen(
        data: &Self::StaticData,
        table: &Self::SampleTable,
        config: &Self::Config,
        rng: &mut impl Rng,
    ) -> Self;
    /// Write this sample to a string
    fn unparse(&self, data: &Self::StaticData, s: &mut String);
    /// Parse a sample from a given string.  This is expected to be an inverse of `unparse`
    fn parse(data: &Self::StaticData, s: &str) -> Option<Self>;
}

pub fn fuzz<'lang, A: Arbitrary<'lang> + std::fmt::Debug>(
    lang: &'lang Lang,
    iteration_limit: Option<usize>,
    config: &A::Config,
) {
    let mut rng = rand::thread_rng();
    let static_data = A::gen_static_data(&lang, config);

    // Stat printing state
    let fuzz_start_time = Instant::now();
    let mut elapsed_secs_for_last_print = 0;

    // Fuzzing loop
    let mut unparsed_string = String::new();
    let mut iterations = 0usize;
    let mut total_bytes_tokenized = 0;
    let mut total_time_tokenizing = Duration::ZERO;
    loop {
        // Generate lookup tables for commonly used samples
        let table = A::gen_table(&static_data, &mut rng, config);

        for _ in 0..1_000 {
            let sample = A::gen(&static_data, &table, config, &mut rng);
            // Unparse the sample
            unparsed_string.clear();
            sample.unparse(&static_data, &mut unparsed_string);
            println!("{:?}", unparsed_string);
            // Parse the string generated by unparsing `sample` (whilst timing the parser).  This
            // is expected to be the same as `sample`
            let start = Instant::now();
            let parsed_sample = A::parse(&static_data, &unparsed_string);
            total_bytes_tokenized += unparsed_string.len();
            total_time_tokenizing += start.elapsed();

            // Check if the parsing passed
            let has_passed = parsed_sample.as_ref() == Some(&sample);
            if !has_passed {
                dbg!(&sample, &unparsed_string, &parsed_sample);
                panic!("Parsing failed!"); // TODO: Shrink inputs
            }

            iterations += 1;
            let reached_iteration_limit =
                iteration_limit.map_or(false, |limit| iterations >= limit);

            // Print stats roughly every second, or when the test ends.  We check the times every
            // few loop iterations to speed up the fuzzing loop.
            let elapsed_secs = fuzz_start_time.elapsed().as_secs();
            if elapsed_secs > elapsed_secs_for_last_print || reached_iteration_limit {
                elapsed_secs_for_last_print = elapsed_secs;
                println!(
                    "{} iters.  {} in {:?} = {}/s",
                    iterations,
                    utils::format_big_bytes(total_bytes_tokenized as f32),
                    total_time_tokenizing,
                    utils::format_big_bytes(
                        total_bytes_tokenized as f32 / total_time_tokenizing.as_secs_f32()
                    )
                );
            }
            // Exit loop if iteration limit is reached
            if reached_iteration_limit {
                return;
            }
        }
    }
}
